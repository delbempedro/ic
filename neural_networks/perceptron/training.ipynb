{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training_qNN.ipynb\n",
    "\n",
    "Notebook that define the necessary functions to traine a qNN and traines it.\n",
    "\n",
    "Dependencies:\n",
    "- Uses trainer_qNN to get trainer qNN object and their functions\n",
    "\n",
    "Since:\n",
    "- 04/2025\n",
    "\n",
    "Authors:\n",
    "- Pedro C. Delbem. <pedrodelbem@usp.br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainer_qNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_grain = 10\n",
    "number_of_inputs = 2\n",
    "tolerance = 0.25\n",
    "logic_gates = [\"AND\", \"OR\", \"XOR\", \"NAND\", \"NOR\", \"XNOR\"]\n",
    "\n",
    "for encoding in [\"amplitude\", \"phase\"]:\n",
    "\n",
    "    for logic_gate in logic_gates:\n",
    "\n",
    "        #create the directory if necessary\n",
    "        name_of_results_directory = Path(f\"results/{encoding}\")\n",
    "        name_of_results_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for method in [\"exhaustive_search\", \"gradient_descent\", \"random_search\", \"simulated_annealing\", \"genetic_algorithm\"]:\n",
    "\n",
    "            #make results file\n",
    "            with open(f\"{name_of_results_directory}/{logic_gate}_{method}_tolerance_{tolerance}_max_of_iterations_{grid_grain**number_of_inputs}.csv\", \"w\") as file:\n",
    "\n",
    "                file.write(\"Logic Gate; Method; Iteration; Error; Run\\n\")\n",
    "                for run in range(10):\n",
    "\n",
    "                    #create trainer\n",
    "                    trainer = trainer_qNN.trainer_qNN(type_of_encoding=encoding, save_history=True, tolerance=tolerance, grid_grain=grid_grain)\n",
    "\n",
    "                    #train qNN\n",
    "                    trainer.train(type_of_training=method)\n",
    "\n",
    "                    for i, error in enumerate(trainer.get_results()[\"History List\"][\"Best Error\"]):\n",
    "\n",
    "                        file.write(f\"{logic_gate}; {method}; {i+1}; {error}; {run}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'encoding = \"phase\"\\ntolerance = 0.0\\ngrid_grain = 100\\nnumber_of_inputs = 2\\ninputs = [\"00\", \"01\", \"10\", \"11\"]\\nname_of_config_file = f\"results_with_counts.cfg\"\\nwith open(f\"results/{name_of_config_file}\", \"w\") as f:\\n    f.write(f\"Results for {encoding} encoding, tolerance={tolerance}, grid_grain={grid_grain}\\n\")\\n    f.write(f\"  Training with exhaustive_search method\\n\")\\n\\nname_of_angles_file = f\"results_angles_file.csv\"\\nwith open(f\"results/{name_of_angles_file}\", \"w\") as f:\\n    number_of_iterations = 0\\n    grid = np.linspace(-np.pi, np.pi, grid_grain)\\n    for parameters in product(grid, repeat=(number_of_inputs+1)):\\n        parameters = [float(x) for x in parameters]\\n        number_of_iterations +=1\\n        f.write(f\"{number_of_iterations}; {parameters[0]}; {parameters[1]}; {parameters[2]}\\n\")'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"encoding = \"phase\"\n",
    "tolerance = 0.0\n",
    "grid_grain = 100\n",
    "number_of_inputs = 2\n",
    "inputs = [\"00\", \"01\", \"10\", \"11\"]\n",
    "name_of_config_file = f\"results_with_counts.cfg\"\n",
    "with open(f\"results/{name_of_config_file}\", \"w\") as f:\n",
    "    f.write(f\"Results for {encoding} encoding, tolerance={tolerance}, grid_grain={grid_grain}\\n\")\n",
    "    f.write(f\"  Training with exhaustive_search method\\n\")\n",
    "\n",
    "name_of_angles_file = f\"results_angles_file.csv\"\n",
    "with open(f\"results/{name_of_angles_file}\", \"w\") as f:\n",
    "    number_of_iterations = 0\n",
    "    grid = np.linspace(-np.pi, np.pi, grid_grain)\n",
    "    for parameters in product(grid, repeat=(number_of_inputs+1)):\n",
    "        parameters = [float(x) for x in parameters]\n",
    "        number_of_iterations +=1\n",
    "        f.write(f\"{number_of_iterations}; {parameters[0]}; {parameters[1]}; {parameters[2]}\\n\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'encoding = \"phase\"\\ntolerance = 0.0\\ngrid_grain = 100\\ninputs = [\"00\", \"01\", \"10\", \"11\"]\\nname_of_result_file = f\"results_with_counts.txt\"\\nwith open(f\"results/{name_of_result_file}\", \"w\") as f:\\n    f.write(f\"Results for {encoding} encoding, tolerance={tolerance}, grid_grain={grid_grain}\\n\")\\n    trainer = trainer_qNN.trainer_qNN(type_of_encoding=encoding, save_history=True, tolerance=tolerance, grid_grain=grid_grain, save_counts=True, save_parameters_history=True)\\n    trainer.train(type_of_training=\"exhaustive_search\")\\n    f.write(f\"  Training with exhaustive_search method\\n\")\\n    f.write(f\"      Iteration; Theta1; Theta2; Alpha; Input 00 Output 0 Frequency; Input 00 Output 1 Frequency; Input 01 Output 0 Frequency; Input 01 Output 1 Frequency; Input 10 Output 0 Frequency; Input 10 Output 1 Frequency; Input 11 Output 0 Frequency; Input 11 Output 1 Frequency; Error\\n\")\\n    for i in range(trainer.get_results()[\"Number of Iterations\"]):\\n        list_of_counts = list(trainer.get_results()[\"Counts List\"][i])\\n        dict_of_counts = {\\'00\\': list_of_counts[0][0], \\'01\\': list_of_counts[1][0], \\'10\\': list_of_counts[2][0], \\'11\\': list_of_counts[3][0]}\\n        parameters = [float(x) for x in trainer.get_results()[\"Parameters History List\"][i]]\\n        string = f\"          {i+1}; {parameters[0]}; {parameters[1]}; {parameters[2]};\"\\n        if \\'0\\' in dict_of_counts[\\'00\\']:\\n            string += f\" {dict_of_counts[\\'00\\'][\\'0\\']};\"\\n        else:\\n            string += f\" 0;\"\\n        if \\'1\\' in dict_of_counts[\\'00\\']:\\n            string += f\" {dict_of_counts[\\'00\\'][\\'1\\']};\"\\n        else:\\n            string += f\" 0;\"\\n        if \\'0\\' in dict_of_counts[\\'01\\']:\\n            string += f\" {dict_of_counts[\\'01\\'][\\'0\\']};\"\\n        else:\\n            string += f\" 0;\"\\n        if \\'1\\' in dict_of_counts[\\'01\\']:\\n            string += f\" {dict_of_counts[\\'01\\'][\\'1\\']};\"\\n        else:\\n            string += f\" 0;\"\\n        if \\'0\\' in dict_of_counts[\\'10\\']:\\n            string += f\" {dict_of_counts[\\'10\\'][\\'0\\']};\"\\n        else:\\n            string += f\" 0;\"\\n        if \\'1\\' in dict_of_counts[\\'10\\']:\\n            string += f\" {dict_of_counts[\\'10\\'][\\'1\\']};\"\\n        else:\\n            string += f\" 0;\"\\n        if \\'0\\' in dict_of_counts[\\'11\\']:\\n            string += f\" {dict_of_counts[\\'11\\'][\\'0\\']};\"\\n        else:\\n            string += f\" 0;\"\\n        if \\'1\\' in dict_of_counts[\\'11\\']:\\n            string += f\" {dict_of_counts[\\'11\\'][\\'1\\']};\"\\n        else:\\n            string += f\" 0;\"\\n        string += f\" {trainer.get_results()[\\'History List\\'][i]}\\n\"\\n        f.write(string)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"encoding = \"phase\"\n",
    "tolerance = 0.0\n",
    "grid_grain = 100\n",
    "inputs = [\"00\", \"01\", \"10\", \"11\"]\n",
    "name_of_result_file = f\"results_with_counts.txt\"\n",
    "with open(f\"results/{name_of_result_file}\", \"w\") as f:\n",
    "    f.write(f\"Results for {encoding} encoding, tolerance={tolerance}, grid_grain={grid_grain}\\n\")\n",
    "    trainer = trainer_qNN.trainer_qNN(type_of_encoding=encoding, save_history=True, tolerance=tolerance, grid_grain=grid_grain, save_counts=True, save_parameters_history=True)\n",
    "    trainer.train(type_of_training=\"exhaustive_search\")\n",
    "    f.write(f\"  Training with exhaustive_search method\\n\")\n",
    "    f.write(f\"      Iteration; Theta1; Theta2; Alpha; Input 00 Output 0 Frequency; Input 00 Output 1 Frequency; Input 01 Output 0 Frequency; Input 01 Output 1 Frequency; Input 10 Output 0 Frequency; Input 10 Output 1 Frequency; Input 11 Output 0 Frequency; Input 11 Output 1 Frequency; Error\\n\")\n",
    "    for i in range(trainer.get_results()[\"Number of Iterations\"]):\n",
    "        list_of_counts = list(trainer.get_results()[\"Counts List\"][i])\n",
    "        dict_of_counts = {'00': list_of_counts[0][0], '01': list_of_counts[1][0], '10': list_of_counts[2][0], '11': list_of_counts[3][0]}\n",
    "        parameters = [float(x) for x in trainer.get_results()[\"Parameters History List\"][i]]\n",
    "        string = f\"          {i+1}; {parameters[0]}; {parameters[1]}; {parameters[2]};\"\n",
    "        if '0' in dict_of_counts['00']:\n",
    "            string += f\" {dict_of_counts['00']['0']};\"\n",
    "        else:\n",
    "            string += f\" 0;\"\n",
    "        if '1' in dict_of_counts['00']:\n",
    "            string += f\" {dict_of_counts['00']['1']};\"\n",
    "        else:\n",
    "            string += f\" 0;\"\n",
    "        if '0' in dict_of_counts['01']:\n",
    "            string += f\" {dict_of_counts['01']['0']};\"\n",
    "        else:\n",
    "            string += f\" 0;\"\n",
    "        if '1' in dict_of_counts['01']:\n",
    "            string += f\" {dict_of_counts['01']['1']};\"\n",
    "        else:\n",
    "            string += f\" 0;\"\n",
    "        if '0' in dict_of_counts['10']:\n",
    "            string += f\" {dict_of_counts['10']['0']};\"\n",
    "        else:\n",
    "            string += f\" 0;\"\n",
    "        if '1' in dict_of_counts['10']:\n",
    "            string += f\" {dict_of_counts['10']['1']};\"\n",
    "        else:\n",
    "            string += f\" 0;\"\n",
    "        if '0' in dict_of_counts['11']:\n",
    "            string += f\" {dict_of_counts['11']['0']};\"\n",
    "        else:\n",
    "            string += f\" 0;\"\n",
    "        if '1' in dict_of_counts['11']:\n",
    "            string += f\" {dict_of_counts['11']['1']};\"\n",
    "        else:\n",
    "            string += f\" 0;\"\n",
    "        string += f\" {trainer.get_results()['History List'][i]}\\n\"\n",
    "        f.write(string)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainer = trainer_qNN.trainer_qNN(type_of_encoding=\"phase\", save_history=True, tolerance=0, grid_grain=4, save_counts=True)\\ntrainer.train(type_of_training=\"exhaustive_search\")\\nprint(trainer.get_results()[\\'Counts List\\'])\\n[list(t) for t in product([0, 1], repeat=2)]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"trainer = trainer_qNN.trainer_qNN(type_of_encoding=\"phase\", save_history=True, tolerance=0, grid_grain=4, save_counts=True)\n",
    "trainer.train(type_of_training=\"exhaustive_search\")\n",
    "print(trainer.get_results()['Counts List'])\n",
    "[list(t) for t in product([0, 1], repeat=2)]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def multi_training(method, times, trainer):\\n    trainer.train(type_of_training=method)\\n    error = 0\\n    iterations = 0\\n    history_list = []\\n    for i in range(times):\\n        trainer.train(type_of_training=method)\\n        error += trainer.get_results()[\"Final Error\"]\\n        iterations += trainer.get_results()[\\'Number of Iterations\\']\\n\\n        count = 0\\n        for j in trainer.get_results()[\"History List\"]:\\n            if len(history_list) <= count:\\n                history_list.append(j)\\n            else:\\n                history_list[count] += j\\n            count += 1\\n    error /= times\\n    iterations /= times\\n    for i in range(len(history_list)):\\n        history_list[i] /= times\\n    return {\"Final Error\": error, \"Number of Iterations\": iterations, \"History List\": history_list}\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def multi_training(method, times, trainer):\n",
    "    trainer.train(type_of_training=method)\n",
    "    error = 0\n",
    "    iterations = 0\n",
    "    history_list = []\n",
    "    for i in range(times):\n",
    "        trainer.train(type_of_training=method)\n",
    "        error += trainer.get_results()[\"Final Error\"]\n",
    "        iterations += trainer.get_results()['Number of Iterations']\n",
    "\n",
    "        count = 0\n",
    "        for j in trainer.get_results()[\"History List\"]:\n",
    "            if len(history_list) <= count:\n",
    "                history_list.append(j)\n",
    "            else:\n",
    "                history_list[count] += j\n",
    "            count += 1\n",
    "    error /= times\n",
    "    iterations /= times\n",
    "    for i in range(len(history_list)):\n",
    "        history_list[i] /= times\n",
    "    return {\"Final Error\": error, \"Number of Iterations\": iterations, \"History List\": history_list}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grid_grain = 10\\ntolerance = 0.05\\nlogic_gates = [\"AND\", \"OR\", \"XOR\", \"NAND\", \"NOR\", \"XNOR\"]\\n\\nfor logic_gate in logic_gates:\\n\\n    for encoding in [\"amplitude\", \"phase\"]:\\n\\n        name_of_result_file = f\"results_{encoding}_{logic_gate}_{tolerance}_{grid_grain}.txt\"\\n        with open(f\"results/{name_of_result_file}\", \"w\") as f:\\n\\n            f.write(f\"Results for {encoding} encoding, tolerance={tolerance}, grid_grain={grid_grain}\\n\")\\n            trainer = trainer_qNN.trainer_qNN(type_of_encoding=encoding, save_history=True, tolerance=tolerance, grid_grain=grid_grain)\\n\\n            for method in [\"exhaustive_search\", \"gradient_descent\", \"random_search\", \"simulated_annealing\", \"genetic_algorithm\"]:\\n\\n                for i in range(10):\\n                    f.write(f\"  Training with {method} method\")\\n                    trainer.train(type_of_training=method)\\n                    #multi_training(method, 10, trainer)\\n                    f.write(f\"      Parameters: {trainer.get_results()[\\'Final Parameters\\']} | Error: {trainer.get_results()[\"Final Error\"]} | Iterations: {trainer.get_results()[\\'Number of Iterations\\']}\\n\")\\n\\n                    f.write(\"       History of errors:\\n\")\\n                    for i, error in enumerate(trainer.get_results()[\"History List\"]):\\n                        f.write(f\"          Iteration {i+1}: Error: {error}\\n\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"grid_grain = 10\n",
    "tolerance = 0.05\n",
    "logic_gates = [\"AND\", \"OR\", \"XOR\", \"NAND\", \"NOR\", \"XNOR\"]\n",
    "\n",
    "for logic_gate in logic_gates:\n",
    "\n",
    "    for encoding in [\"amplitude\", \"phase\"]:\n",
    "\n",
    "        name_of_result_file = f\"results_{encoding}_{logic_gate}_{tolerance}_{grid_grain}.txt\"\n",
    "        with open(f\"results/{name_of_result_file}\", \"w\") as f:\n",
    "\n",
    "            f.write(f\"Results for {encoding} encoding, tolerance={tolerance}, grid_grain={grid_grain}\\n\")\n",
    "            trainer = trainer_qNN.trainer_qNN(type_of_encoding=encoding, save_history=True, tolerance=tolerance, grid_grain=grid_grain)\n",
    "\n",
    "            for method in [\"exhaustive_search\", \"gradient_descent\", \"random_search\", \"simulated_annealing\", \"genetic_algorithm\"]:\n",
    "\n",
    "                for i in range(10):\n",
    "                    f.write(f\"  Training with {method} method\")\n",
    "                    trainer.train(type_of_training=method)\n",
    "                    #multi_training(method, 10, trainer)\n",
    "                    f.write(f\"      Parameters: {trainer.get_results()['Final Parameters']} | Error: {trainer.get_results()[\"Final Error\"]} | Iterations: {trainer.get_results()['Number of Iterations']}\\n\")\n",
    "\n",
    "                    f.write(\"       History of errors:\\n\")\n",
    "                    for i, error in enumerate(trainer.get_results()[\"History List\"]):\n",
    "                        f.write(f\"          Iteration {i+1}: Error: {error}\\n\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
